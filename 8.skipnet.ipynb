{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from utils.folder import ImageFolder\n",
    "from utils.common_utils import *\n",
    "import visdom\n",
    "import numpy as np\n",
    "\n",
    "vis = visdom.Visdom()\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "#         transforms.Grayscale(num_output_channels=3),\n",
    "#         transforms.Resize(400),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5, 0.75], [0.225, 0.225, 0.225,0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "#         transforms.Grayscale(num_output_channels=3),\n",
    "#         transforms.Resize(400),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "#         transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5, 0.75], [0.225, 0.225, 0.225, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'data'\n",
    "image_datasets = {x: ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=1)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 15, 'val': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pil_loader(path):\n",
    "#     # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "#     with open(path, 'rb') as f:\n",
    "#         img = Image.open(f)\n",
    "#         return img.convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize a few images\n",
    "^^^^^^^^^^^^^^^^^^^^^^\n",
    "Let's visualize a few training images so as to understand the data\n",
    "augmentations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5749) tensor(0.7762) tensor(0.9530) tensor(0.8972)\n",
      "tensor(-1.6213) tensor(-1.0976) tensor(-0.6128) tensor(-0.6325)\n",
      "1.1111112\n",
      "-1.1023964\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "#     mean = np.array([0.485, 0.456, 0.406])\n",
    "#     std = np.array([0.229, 0.224, 0.225])\n",
    "#     inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "_inputs, classes = next(iter(dataloaders['train']))\n",
    "# print(\"_inputs.shape=\",_inputs.shape)\n",
    "# Make a grid from batch\n",
    "inputs = _inputs[:,0:3,:,:]\n",
    "alphas = _inputs[:,3:4,:,:]\n",
    "stdr = torch.std(torch.FloatTensor(_inputs[:,0,:,:]))\n",
    "stdg = torch.std(torch.FloatTensor(_inputs[:,1,:,:]))\n",
    "stdb = torch.std(torch.FloatTensor(_inputs[:,2,:,:]))\n",
    "stda = torch.std(torch.FloatTensor(_inputs[:,3,:,:]))\n",
    "\n",
    "meanr = torch.mean(torch.FloatTensor(_inputs[:,0,:,:]))\n",
    "meang = torch.mean(torch.FloatTensor(_inputs[:,1,:,:]))\n",
    "meanb = torch.mean(torch.FloatTensor(_inputs[:,2,:,:]))\n",
    "meana = torch.mean(torch.FloatTensor(_inputs[:,3,:,:]))\n",
    "\n",
    "print(stdr,stdg,stdb,stda)\n",
    "print(meanr,meang,meanb,meana)\n",
    "# print(alphas)\n",
    "print(np.max(alphas.numpy()))\n",
    "print(np.min(alphas.numpy()))\n",
    "# print(\"inputs.shape=\",inputs.shape)\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "# print(out.shape)\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis.image(out,win='in')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model\n",
    "------------------\n",
    "\n",
    "Now, let's write a general function to train a model. Here, we will\n",
    "illustrate:\n",
    "\n",
    "-  Scheduling the learning rate\n",
    "-  Saving the best model\n",
    "\n",
    "In the following, parameter ``scheduler`` is an LR scheduler object from\n",
    "``torch.optim.lr_scheduler``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGBAShow(rgb_np,a_np1=None,a_np2=None,phase = ''):\n",
    "    return\n",
    "    vis.image(rgb_np,win = phase+'rgb',opts=dict(title=phase+'rgb'))\n",
    "    if a_np1 is not None:\n",
    "        #out_np1 = np.concatenate((rgb_np,a_np1),axis=0)\n",
    "        out_np1 = rgb_np*a_np1\n",
    "#         vis.image(out_np1,win = phase+'a1',opts=dict(title=phase+'a1'))\n",
    "        vis.image(a_np1*255,win = phase+'a1_mask',opts=dict(title=phase+'a1_mask'))\n",
    "    if a_np2 is not None:\n",
    "        #out_np2 = np.concatenate((rgb_np,a_np2),axis=0)\n",
    "        out_np2 = rgb_np*a_np2\n",
    "#         vis.image(out_np2,win = phase+'a2',opts=dict(title=phase+'a2'))\n",
    "        vis.image((a_np2+1)*0.5*255,win = phase+'a2_mask',opts=dict(title=phase+'a2_mask'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLosses():\n",
    "    plt.plot(all_losses['train'],label='train')\n",
    "    plt.plot(all_losses['val'],label='val')\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 0.0\n",
    "    all_losses={'train':[],'val':[]}\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                # get the inputs ,labels没有用，只是必须有这层结构\n",
    "                _inputs, labels = data\n",
    "                #把alpha通道拆出来，作为label,剩下的作为rgb3通道input\n",
    "#                 print('_inputs.shape=',_inputs.shape)\n",
    "                inputs = (_inputs[:,0:3,:,:].sum(1)*0.3).reshape(4,1,224,224)\n",
    "                labels = _inputs[:,3:4,:,:]\n",
    "#                 labels = (labels-0.5)*2\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                #print('outputs mean =',torch.mean(outputs),torch.min(outputs),torch.max(outputs))\n",
    "                #print('========= outputs===================',outputs[0])\n",
    "                loss = criterion(outputs, labels)\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data.item() * inputs.size(0)\n",
    "                #show sample\n",
    "                RGBAShow(inputs.cpu().detach().numpy()[0], a_np1= labels.cpu().detach().numpy()[0], a_np2 = outputs.cpu().detach().numpy()[0],phase = phase)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            all_losses[phase].append(epoch_loss)\n",
    "            print('{} Loss: {:.4f}'.format(\n",
    "                phase, epoch_loss))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'train' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "\n",
    "            \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "#     print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model,all_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuning the convnet\n",
    "----------------------\n",
    "\n",
    "Load a pretrained model and reset final fully connected layer.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.skip import skip\n",
    "pad = 'reflection'\n",
    "OPT_OVER = 'net' # 'net,input'\n",
    "reg_noise_std = 1./30. # set to 1./20. for sigma=50\n",
    "LR = 0.01\n",
    "OPTIMIZER='adam' # 'LBFGS'\n",
    "show_every = 500\n",
    "num_iter=2400\n",
    "input_depth = 3\n",
    "figsize = 5 \n",
    "dtype = (torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor)\n",
    "\n",
    "net = skip(\n",
    "            input_depth, 1, \n",
    "            num_channels_down = [8, 16, 32, 64, 128 ], \n",
    "            num_channels_up   = [8, 16, 32, 64, 128 ],\n",
    "            num_channels_skip = [4,  4,  4,  4,   4], \n",
    "            upsample_mode='bilinear',\n",
    "            need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU')\n",
    "\n",
    "net = net.type(dtype)\n",
    "# print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in net.parameters():\n",
    "#     print(type(param.data), param.size())\n",
    "#     print(param.data)\n",
    "\n",
    "# s = sum([np.prod(list(p.size())) for p in net.parameters() ])\n",
    "# print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights initializing is far important than you imaging\n",
    "# learn from inpainting\n",
    "for n in [x for x in net.parameters()]:\n",
    "    n.data.normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = net\n",
    "\n",
    "if use_gpu:\n",
    "    model_ft = model_ft.cuda()\n",
    "\n",
    "criterion = nn.MSELoss().type(dtype)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate\n",
    "^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "It should take around 15-25 min on CPU. On GPU though, it takes less than a\n",
    "minute.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight[4, 3, 1, 1], so expected input[4, 1, 224, 224] to have 3 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5dfb0cc24d6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model_ft,all_losses = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[0;32m----> 2\u001b[0;31m                        num_epochs=20)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-9301dc2a3880>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;31m#print('outputs mean =',torch.mean(outputs),torch.min(outputs),torch.max(outputs))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deeplearning/rsmask/models/common.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0minputs_shapes2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight[4, 3, 1, 1], so expected input[4, 1, 224, 224] to have 3 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "model_ft,all_losses = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLosses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show a picture \n",
    "\n",
    "# Get a batch of training data\n",
    "_inputs, classes = next(iter(dataloaders['train']))\n",
    "print(\"_inputs.shape=\",_inputs.shape)\n",
    "# Make a grid from batch\n",
    "inputs = _inputs[:,0:3,:,:]\n",
    "\n",
    "# print(inputs[0])\n",
    "inputs_a = _inputs[:,3:4,:,:]\n",
    "if use_gpu:\n",
    "    inputs = Variable(inputs.cuda())\n",
    "\n",
    "model_ft.train(False)    \n",
    "outs = model_ft(inputs)\n",
    "\n",
    "# print(outs.cpu()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_batch = inputs.cpu().detach().numpy()\n",
    "np_to_pil(rgb_batch[0]).save('rgb.jpg')\n",
    "\n",
    "a2_batch = outs.cpu().detach().numpy()\n",
    "a1_batch = inputs_a.cpu().detach().numpy()\n",
    "rgba_batch = np.concatenate((rgb_batch,a2_batch),axis=1)\n",
    "\n",
    "rgba_np=rgba_batch[0]\n",
    "rgba_pil = np_to_pil(rgba_np)\n",
    "rgba_pil.show()\n",
    "rgba_pil.save('rgba.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rgb_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b3b0518a16cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mRGBAShow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma_np1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma1_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma_np2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma2_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'rgb_batch' is not defined"
     ]
    }
   ],
   "source": [
    "RGBAShow(rgb_batch[0],a_np1=a1_batch[0],a_np2=a2_batch[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def RGBAShowBatch(rgb_np,a_np):\n",
    "#     out_np = np.concatenate((rgb_np,a_np),axis=1)\n",
    "#     vis.images(out_np,win='out',opts=dict(caption='out list'),)\n",
    "\n",
    "# RGBAShowBatch(rgb_batch,a_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a2_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-8d39e75ec84b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma2_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a2_batch' is not defined"
     ]
    }
   ],
   "source": [
    "np.min(a2_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_to_pil(inputs.cpu().detach().numpy()[0]).save('input.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_inputs, classes = next(iter(dataloaders['train']))\n",
    "ii = _inputs.cpu().detach().numpy()[0]\n",
    "print(ii.shape)\n",
    "# print(ii[0])\n",
    "# print(ii[1])\n",
    "# print(ii[2])\n",
    "\n",
    "\n",
    "def dumpnp(a):\n",
    "    for h in range(a.shape[0]):\n",
    "        print('[{0}]'.format(h),end='')\n",
    "        for i in range (a.shape[1]):\n",
    "            print('[{0}][{1}]'.format(h,i),end='')\n",
    "            for j in range(a.shape[2]):\n",
    "                print(a[h][i][j],',',end='')\n",
    "            print(\"\")\n",
    "        print(\"\")\n",
    "def dumpnp2(a):\n",
    "    for i in range (a.shape[1]):\n",
    "        print('[{0}]'.format(i),end='')\n",
    "        for j in range(a.shape[2]):\n",
    "            print(a[0][i][j]+a[1][i][j]+a[2][i][j],',',end='')\n",
    "        print(\"\")\n",
    "    print(\"\")\n",
    "                \n",
    "dumpnp2(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_to_pil(ii[0:3,:,:]).save('_input.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
